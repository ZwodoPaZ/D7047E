{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import data_loading_code as pre\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " # get data, pre-process and split\n",
    "data = pre.pd.read_csv(\"amazon_cells_labelled.txt\", delimiter='\\t', header=None)\n",
    "data.columns = ['Sentence', 'Class']\n",
    "data['index'] = data.index                                          # add new column index\n",
    "columns = ['index', 'Class', 'Sentence']\n",
    "data = pre.preprocess_pandas(data, columns)                             # pre-process\n",
    "training_data, validation_data, training_labels, validation_labels = pre.train_test_split( # split the data into training, validation, and test splits\n",
    "    data['Sentence'].values.astype('U'),\n",
    "    data['Class'].values.astype('int32'),\n",
    "    test_size=0.10,\n",
    "    random_state=0,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# vectorize data using TFIDF and transform for PyTorch for scalability\n",
    "word_vectorizer = pre.TfidfVectorizer(analyzer='word', ngram_range=(1,2), max_features=50000, max_df=0.5, use_idf=True, norm='l2')\n",
    "training_data = word_vectorizer.fit_transform(training_data)        # transform texts to sparse matrix\n",
    "training_data = training_data.todense()                             # convert to dense matrix for Pytorch\n",
    "vocab_size = len(word_vectorizer.vocabulary_)\n",
    "validation_data = word_vectorizer.transform(validation_data)\n",
    "validation_data = validation_data.todense()\n",
    "train_x_tensor = torch.from_numpy(np.array(training_data)).type(torch.FloatTensor)\n",
    "train_y_tensor = torch.from_numpy(np.array(training_labels)).long()\n",
    "validation_x_tensor = torch.from_numpy(np.array(validation_data)).type(torch.FloatTensor)\n",
    "validation_y_tensor = torch.from_numpy(np.array(validation_labels)).long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "torch.set_printoptions(threshold=10_000)\n",
    "print(len(training_data))\n",
    "\n",
    "print(train_y_tensor[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "        nn.Linear(vocab_size,1000),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(1000,100),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(100,25),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(25,2)\n",
    "        )\n",
    "    \n",
    "    def feedforward(self,input):\n",
    "        return self.network(input)\n",
    "    \n",
    "    \n",
    "def backward(model, epochs, optimizer, loss_function, train_x_tensor, train_y_tensor, validation_x_tensor, validation_y_tensor):\n",
    "    train_Acc = 0\n",
    "    train_Acc = 0\n",
    "    validation_AccV = 0\n",
    "    best_loss = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        trainCorr = 0\n",
    "        valCorr = 0\n",
    "        for (sentens, labels) in zip(train_x_tensor,train_y_tensor):\n",
    "            pred = model.feedforward(sentens)\n",
    "            \n",
    "            loss = loss_function(pred, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if best_loss > loss.item():\n",
    "                best_loss = loss.item()\n",
    "                best_model = torch.save(\"nlpBest\")\n",
    "                \n",
    "            pred = torch.argmax(F.softmax(pred))\n",
    "            trainCorr += torch.sum(pred==labels).item()\n",
    "            train_Acc = trainCorr/len(training_data)\n",
    "            \n",
    "        model.eval()\n",
    "        with torch.no_grad():   \n",
    "            for (sentensv, labelsv) in zip(validation_x_tensor,validation_y_tensor):\n",
    "                \n",
    "                predv = model.feedforward(sentensv)\n",
    "                lossv = loss_function(predv,labelsv)\n",
    "                \n",
    "                predv = torch.argmax(F.softmax(predv))\n",
    "                valCorr += torch.sum(predv==labelsv).item()\n",
    "                validation_AccV = valCorr/len(validation_data)\n",
    "        print(\"epoch:\", epoch, \"Loss Training:\", loss.item(), \"Training acc:\", train_Acc)\n",
    "        print(\"epoch:\", epoch, \"Loss Validation:\", lossv.item(),\"Validation acc:\", validation_AccV)\n",
    "    return best_model\n",
    "        \n",
    "        \n",
    "    \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implemntation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harry\\AppData\\Local\\Temp\\ipykernel_25428\\2668272655.py:39: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred = torch.argmax(F.softmax(pred))\n",
      "C:\\Users\\harry\\AppData\\Local\\Temp\\ipykernel_25428\\2668272655.py:50: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  predv = torch.argmax(F.softmax(predv))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 Loss Training: 0.5135350823402405 Training acc: 0.7111111111111111\n",
      "epoch: 0 Loss Validation: 0.017608271911740303 Validation acc: 0.86\n",
      "epoch: 1 Loss Training: 0.00019500737835187465 Training acc: 0.9844444444444445\n",
      "epoch: 1 Loss Validation: 9.536738616588991e-07 Validation acc: 0.85\n",
      "epoch: 2 Loss Training: 1.2397689715726301e-05 Training acc: 1.0\n",
      "epoch: 2 Loss Validation: 1.1920928244535389e-07 Validation acc: 0.85\n",
      "epoch: 3 Loss Training: 3.6954811548639555e-06 Training acc: 1.0\n",
      "epoch: 3 Loss Validation: 0.0 Validation acc: 0.85\n",
      "epoch: 4 Loss Training: 1.5497195136049413e-06 Training acc: 1.0\n",
      "epoch: 4 Loss Validation: 0.0 Validation acc: 0.85\n",
      "epoch: 5 Loss Training: 7.152555099310121e-07 Training acc: 1.0\n",
      "epoch: 5 Loss Validation: 0.0 Validation acc: 0.84\n",
      "epoch: 6 Loss Training: 3.576278118089249e-07 Training acc: 1.0\n",
      "epoch: 6 Loss Validation: 0.0 Validation acc: 0.84\n",
      "epoch: 7 Loss Training: 2.3841855067985307e-07 Training acc: 1.0\n",
      "epoch: 7 Loss Validation: 0.0 Validation acc: 0.84\n",
      "epoch: 8 Loss Training: 1.1920928244535389e-07 Training acc: 1.0\n",
      "epoch: 8 Loss Validation: 0.0 Validation acc: 0.84\n",
      "epoch: 9 Loss Training: 1.1920928244535389e-07 Training acc: 1.0\n",
      "epoch: 9 Loss Validation: 0.0 Validation acc: 0.84\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "model = Net()\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "trained_model = backward(model, epochs, optimizer, criterion, train_x_tensor, train_y_tensor, validation_x_tensor, validation_y_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
