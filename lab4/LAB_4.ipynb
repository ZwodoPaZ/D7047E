{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a33234d-d2a8-4c7d-ac30-c993fc498d31",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: opencv-python 4.11.0.86\n",
      "Uninstalling opencv-python-4.11.0.86:\n",
      "  Successfully uninstalled opencv-python-4.11.0.86\n",
      "Found existing installation: opencv-python-headless 4.11.0.86\n",
      "Uninstalling opencv-python-headless-4.11.0.86:\n",
      "  Successfully uninstalled opencv-python-headless-4.11.0.86\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting opencv-python-headless\n",
      "  Using cached opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless) (2.1.3)\n",
      "Using cached opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
      "Installing collected packages: opencv-python-headless\n",
      "Successfully installed opencv-python-headless-4.11.0.86\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y opencv-python opencv-python-headless\n",
    "!pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4692eed-572b-473c-85d1-ceeda9a60911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.11.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c659fa4c-ac25-45b6-8cd8-41079838e65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning-rate:  0.0001\n",
      "timesteps:  10000000\n",
      "buffer:  100000\n",
      "exploration :  0.1\n",
      "end e:  0.01\n",
      "seed :  1\n"
     ]
    }
   ],
   "source": [
    "#from typing import Any\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import gymnasium as gym  #make sure you're using gymnasium\n",
    "from gymnasium.wrappers import RecordVideo, RecordEpisodeStatistics\n",
    "\n",
    "#import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# stable_baselines3 have wrappers that simplifies\n",
    "# the preprocessing a lot, read more about them here:\n",
    "# https://stable-baselines3.readthedocs.io/en/master/common/atari_wrappers.html\n",
    "from stable_baselines3.common.atari_wrappers import (\n",
    "    ClipRewardEnv,\n",
    "    EpisodicLifeEnv,\n",
    "    FireResetEnv,\n",
    "    MaxAndSkipEnv,\n",
    "    NoopResetEnv,\n",
    ")\n",
    "from stable_baselines3.common.buffers import ReplayBuffer\n",
    "import stable_baselines3.common.atari_wrappers\n",
    "from ale_py import ALEInterface\n",
    "ale = ALEInterface()\n",
    "from stable_baselines3.common.atari_wrappers import WarpFrame\n",
    "from gymnasium.wrappers import FrameStackObservation\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "import hyperparameters0\n",
    "\n",
    "# Instantiate the class\n",
    "params = hyperparameters0.Hyperparameters()\n",
    "\n",
    "# Access attributes\n",
    "print(f\"learning-rate: \", params.learning_rate)  # Should print something like 5e-3\n",
    "print(f\"timesteps: \", params.total_timesteps) #Should print like 10 000 ish\n",
    "print(f\"buffer: \", params.buffer_size) #100\n",
    "print(f\"exploration : \",params.exploration_fraction)\n",
    "print(f\"end e: \", params.end_e)\n",
    "print(f\"seed : \", params.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d592b68-d4c4-4d83-b3bd-5bb8953b7314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "cuda\n",
      "global_step=113, episodic_return=[0.]\n",
      "global_step=255, episodic_return=[1.]\n",
      "global_step=401, episodic_return=[1.]\n",
      "global_step=642, episodic_return=[3.]\n",
      "global_step=816, episodic_return=[2.]\n",
      "global_step=1031, episodic_return=[2.]\n",
      "global_step=1195, episodic_return=[1.]\n",
      "global_step=1437, episodic_return=[3.]\n",
      "global_step=1599, episodic_return=[1.]\n",
      "global_step=1792, episodic_return=[2.]\n",
      "global_step=1912, episodic_return=[0.]\n",
      "global_step=2028, episodic_return=[0.]\n",
      "global_step=2176, episodic_return=[1.]\n",
      "global_step=2294, episodic_return=[0.]\n",
      "global_step=2515, episodic_return=[3.]\n",
      "global_step=2663, episodic_return=[1.]\n",
      "global_step=2781, episodic_return=[0.]\n",
      "global_step=3044, episodic_return=[3.]\n",
      "global_step=3164, episodic_return=[0.]\n",
      "global_step=3426, episodic_return=[3.]\n",
      "global_step=3546, episodic_return=[0.]\n",
      "global_step=3710, episodic_return=[1.]\n",
      "global_step=3828, episodic_return=[0.]\n",
      "global_step=3992, episodic_return=[1.]\n",
      "global_step=4156, episodic_return=[1.]\n",
      "global_step=4272, episodic_return=[0.]\n",
      "global_step=4439, episodic_return=[1.]\n",
      "global_step=4667, episodic_return=[3.]\n",
      "global_step=4787, episodic_return=[0.]\n",
      "global_step=5001, episodic_return=[2.]\n",
      "global_step=5121, episodic_return=[0.]\n",
      "global_step=5335, episodic_return=[2.]\n",
      "global_step=5530, episodic_return=[2.]\n",
      "global_step=5650, episodic_return=[0.]\n",
      "global_step=5768, episodic_return=[0.]\n",
      "global_step=5886, episodic_return=[0.]\n",
      "global_step=6082, episodic_return=[2.]\n",
      "global_step=6286, episodic_return=[3.]\n",
      "global_step=6574, episodic_return=[4.]\n",
      "global_step=6815, episodic_return=[3.]\n",
      "global_step=6933, episodic_return=[0.]\n",
      "global_step=7132, episodic_return=[2.]\n",
      "global_step=7296, episodic_return=[1.]\n",
      "global_step=7460, episodic_return=[1.]\n",
      "global_step=7720, episodic_return=[3.]\n",
      "global_step=8059, episodic_return=[5.]\n",
      "global_step=8179, episodic_return=[0.]\n",
      "global_step=8345, episodic_return=[1.]\n",
      "global_step=8510, episodic_return=[1.]\n",
      "global_step=8724, episodic_return=[2.]\n",
      "global_step=9017, episodic_return=[4.]\n",
      "global_step=9225, episodic_return=[2.]\n",
      "global_step=9436, episodic_return=[2.]\n",
      "global_step=9726, episodic_return=[4.]\n",
      "global_step=9870, episodic_return=[1.]\n",
      "global_step=10060, episodic_return=[2.]\n",
      "global_step=10256, episodic_return=[2.]\n",
      "global_step=10374, episodic_return=[0.]\n",
      "global_step=10587, episodic_return=[2.]\n",
      "global_step=10707, episodic_return=[0.]\n",
      "global_step=11050, episodic_return=[5.]\n",
      "global_step=11168, episodic_return=[0.]\n",
      "global_step=11333, episodic_return=[1.]\n",
      "global_step=11451, episodic_return=[0.]\n",
      "global_step=11569, episodic_return=[0.]\n",
      "global_step=11689, episodic_return=[0.]\n",
      "global_step=11807, episodic_return=[0.]\n",
      "global_step=11973, episodic_return=[1.]\n",
      "global_step=12139, episodic_return=[1.]\n",
      "global_step=12330, episodic_return=[2.]\n",
      "global_step=12448, episodic_return=[0.]\n",
      "global_step=12689, episodic_return=[3.]\n",
      "global_step=12853, episodic_return=[1.]\n",
      "global_step=12971, episodic_return=[0.]\n",
      "global_step=13137, episodic_return=[1.]\n",
      "global_step=13301, episodic_return=[1.]\n",
      "global_step=13676, episodic_return=[6.]\n",
      "global_step=13796, episodic_return=[0.]\n",
      "global_step=14036, episodic_return=[3.]\n",
      "global_step=14156, episodic_return=[0.]\n",
      "global_step=14367, episodic_return=[2.]\n",
      "global_step=14485, episodic_return=[0.]\n",
      "global_step=14603, episodic_return=[0.]\n",
      "global_step=14749, episodic_return=[1.]\n",
      "global_step=15063, episodic_return=[4.]\n",
      "global_step=15356, episodic_return=[4.]\n",
      "global_step=15476, episodic_return=[0.]\n",
      "global_step=15594, episodic_return=[0.]\n",
      "global_step=16132, episodic_return=[13.]\n",
      "global_step=16447, episodic_return=[4.]\n",
      "global_step=16591, episodic_return=[1.]\n",
      "global_step=16739, episodic_return=[1.]\n",
      "global_step=16949, episodic_return=[2.]\n",
      "global_step=17065, episodic_return=[0.]\n",
      "global_step=17325, episodic_return=[4.]\n",
      "global_step=17538, episodic_return=[2.]\n",
      "global_step=17658, episodic_return=[0.]\n",
      "global_step=17774, episodic_return=[0.]\n",
      "global_step=17894, episodic_return=[0.]\n",
      "global_step=18012, episodic_return=[0.]\n",
      "global_step=18225, episodic_return=[2.]\n",
      "global_step=18339, episodic_return=[0.]\n",
      "global_step=18487, episodic_return=[1.]\n",
      "global_step=18605, episodic_return=[0.]\n",
      "global_step=18721, episodic_return=[0.]\n",
      "global_step=18841, episodic_return=[0.]\n",
      "global_step=18961, episodic_return=[0.]\n",
      "global_step=19154, episodic_return=[2.]\n",
      "global_step=19302, episodic_return=[1.]\n",
      "global_step=19495, episodic_return=[2.]\n",
      "global_step=19613, episodic_return=[0.]\n",
      "global_step=19729, episodic_return=[0.]\n",
      "global_step=19894, episodic_return=[1.]\n",
      "global_step=20058, episodic_return=[1.]\n",
      "global_step=20275, episodic_return=[2.]\n",
      "global_step=20391, episodic_return=[0.]\n",
      "global_step=20582, episodic_return=[2.]\n",
      "global_step=20776, episodic_return=[2.]\n",
      "global_step=20896, episodic_return=[0.]\n",
      "global_step=21042, episodic_return=[1.]\n",
      "global_step=21158, episodic_return=[0.]\n",
      "global_step=21377, episodic_return=[3.]\n",
      "global_step=21495, episodic_return=[0.]\n",
      "global_step=21657, episodic_return=[1.]\n",
      "global_step=21946, episodic_return=[4.]\n",
      "global_step=22066, episodic_return=[0.]\n",
      "global_step=22184, episodic_return=[0.]\n",
      "global_step=22302, episodic_return=[0.]\n",
      "global_step=22418, episodic_return=[0.]\n",
      "global_step=22586, episodic_return=[1.]\n",
      "global_step=22807, episodic_return=[3.]\n",
      "global_step=22971, episodic_return=[1.]\n",
      "global_step=23089, episodic_return=[0.]\n",
      "global_step=23235, episodic_return=[1.]\n",
      "global_step=23544, episodic_return=[4.]\n",
      "global_step=23737, episodic_return=[2.]\n",
      "global_step=24059, episodic_return=[8.]\n",
      "global_step=24434, episodic_return=[6.]\n",
      "global_step=24627, episodic_return=[2.]\n",
      "global_step=24795, episodic_return=[1.]\n",
      "global_step=25112, episodic_return=[5.]\n",
      "global_step=25276, episodic_return=[1.]\n",
      "global_step=25396, episodic_return=[0.]\n",
      "global_step=25737, episodic_return=[5.]\n",
      "global_step=25857, episodic_return=[0.]\n",
      "global_step=25977, episodic_return=[0.]\n",
      "global_step=26097, episodic_return=[0.]\n",
      "global_step=26215, episodic_return=[0.]\n",
      "global_step=26535, episodic_return=[5.]\n",
      "global_step=26655, episodic_return=[0.]\n",
      "global_step=26819, episodic_return=[1.]\n",
      "global_step=27032, episodic_return=[2.]\n",
      "global_step=27194, episodic_return=[1.]\n",
      "global_step=27312, episodic_return=[0.]\n",
      "global_step=27430, episodic_return=[0.]\n",
      "global_step=27623, episodic_return=[2.]\n",
      "global_step=27771, episodic_return=[1.]\n",
      "global_step=27937, episodic_return=[1.]\n",
      "global_step=28081, episodic_return=[1.]\n",
      "global_step=28369, episodic_return=[4.]\n",
      "global_step=28487, episodic_return=[0.]\n",
      "global_step=28607, episodic_return=[0.]\n",
      "global_step=28800, episodic_return=[2.]\n",
      "global_step=28918, episodic_return=[0.]\n",
      "global_step=29036, episodic_return=[0.]\n",
      "global_step=29350, episodic_return=[4.]\n",
      "global_step=29466, episodic_return=[0.]\n",
      "global_step=29772, episodic_return=[4.]\n",
      "global_step=29890, episodic_return=[0.]\n",
      "global_step=30111, episodic_return=[3.]\n",
      "global_step=30273, episodic_return=[1.]\n",
      "global_step=30391, episodic_return=[0.]\n",
      "global_step=30631, episodic_return=[3.]\n",
      "global_step=30795, episodic_return=[1.]\n",
      "global_step=30959, episodic_return=[1.]\n",
      "global_step=31222, episodic_return=[3.]\n",
      "global_step=31342, episodic_return=[0.]\n",
      "global_step=31535, episodic_return=[2.]\n",
      "global_step=31825, episodic_return=[4.]\n",
      "global_step=31989, episodic_return=[1.]\n",
      "global_step=32157, episodic_return=[1.]\n",
      "global_step=32469, episodic_return=[4.]\n",
      "global_step=32589, episodic_return=[0.]\n",
      "global_step=32781, episodic_return=[2.]\n",
      "global_step=32901, episodic_return=[0.]\n",
      "global_step=33162, episodic_return=[4.]\n",
      "global_step=33546, episodic_return=[6.]\n",
      "global_step=33938, episodic_return=[6.]\n",
      "global_step=34056, episodic_return=[0.]\n",
      "global_step=34176, episodic_return=[0.]\n",
      "global_step=34391, episodic_return=[2.]\n",
      "global_step=34555, episodic_return=[1.]\n",
      "global_step=34720, episodic_return=[1.]\n",
      "global_step=34985, episodic_return=[3.]\n",
      "global_step=35105, episodic_return=[0.]\n",
      "global_step=35359, episodic_return=[4.]\n",
      "global_step=35649, episodic_return=[4.]\n",
      "global_step=35763, episodic_return=[0.]\n",
      "global_step=35925, episodic_return=[1.]\n",
      "global_step=36188, episodic_return=[3.]\n",
      "global_step=36429, episodic_return=[3.]\n",
      "global_step=36545, episodic_return=[0.]\n",
      "global_step=36736, episodic_return=[2.]\n",
      "global_step=36953, episodic_return=[2.]\n",
      "global_step=37115, episodic_return=[1.]\n",
      "global_step=37279, episodic_return=[1.]\n",
      "global_step=37443, episodic_return=[1.]\n",
      "global_step=37607, episodic_return=[1.]\n",
      "global_step=37818, episodic_return=[2.]\n",
      "global_step=38031, episodic_return=[2.]\n",
      "global_step=38151, episodic_return=[0.]\n",
      "global_step=38269, episodic_return=[0.]\n",
      "global_step=38557, episodic_return=[4.]\n",
      "global_step=38673, episodic_return=[0.]\n",
      "global_step=38793, episodic_return=[0.]\n",
      "global_step=39034, episodic_return=[3.]\n",
      "global_step=39152, episodic_return=[0.]\n",
      "global_step=39369, episodic_return=[2.]\n",
      "global_step=39485, episodic_return=[0.]\n",
      "global_step=39605, episodic_return=[0.]\n",
      "global_step=39772, episodic_return=[1.]\n",
      "global_step=39892, episodic_return=[0.]\n",
      "global_step=40012, episodic_return=[0.]\n",
      "global_step=40130, episodic_return=[0.]\n",
      "global_step=40250, episodic_return=[0.]\n",
      "global_step=40542, episodic_return=[4.]\n",
      "global_step=40711, episodic_return=[1.]\n",
      "global_step=40982, episodic_return=[4.]\n",
      "global_step=41144, episodic_return=[1.]\n",
      "global_step=41310, episodic_return=[1.]\n",
      "global_step=41555, episodic_return=[3.]\n",
      "global_step=41675, episodic_return=[0.]\n",
      "global_step=41795, episodic_return=[0.]\n",
      "global_step=41913, episodic_return=[0.]\n",
      "global_step=42077, episodic_return=[1.]\n",
      "global_step=42338, episodic_return=[3.]\n",
      "global_step=42504, episodic_return=[1.]\n",
      "global_step=42747, episodic_return=[3.]\n",
      "global_step=43007, episodic_return=[3.]\n",
      "global_step=43127, episodic_return=[0.]\n",
      "global_step=43273, episodic_return=[1.]\n",
      "global_step=43391, episodic_return=[0.]\n",
      "global_step=43537, episodic_return=[1.]\n",
      "global_step=43800, episodic_return=[3.]\n",
      "global_step=44088, episodic_return=[4.]\n",
      "global_step=44202, episodic_return=[0.]\n",
      "global_step=44371, episodic_return=[1.]\n",
      "global_step=44840, episodic_return=[8.]\n",
      "global_step=44958, episodic_return=[0.]\n",
      "global_step=45076, episodic_return=[0.]\n",
      "global_step=45397, episodic_return=[5.]\n",
      "global_step=45634, episodic_return=[3.]\n",
      "global_step=45754, episodic_return=[0.]\n",
      "global_step=46021, episodic_return=[4.]\n",
      "global_step=46141, episodic_return=[0.]\n",
      "global_step=46285, episodic_return=[1.]\n",
      "global_step=46403, episodic_return=[0.]\n",
      "global_step=46596, episodic_return=[2.]\n",
      "global_step=46937, episodic_return=[5.]\n",
      "global_step=47057, episodic_return=[0.]\n",
      "global_step=47317, episodic_return=[3.]\n",
      "global_step=47435, episodic_return=[0.]\n",
      "global_step=47628, episodic_return=[2.]\n",
      "global_step=47790, episodic_return=[1.]\n",
      "global_step=47956, episodic_return=[1.]\n",
      "global_step=48072, episodic_return=[0.]\n",
      "global_step=48192, episodic_return=[0.]\n",
      "global_step=48312, episodic_return=[0.]\n",
      "global_step=48430, episodic_return=[0.]\n",
      "global_step=48875, episodic_return=[8.]\n",
      "global_step=49040, episodic_return=[1.]\n",
      "global_step=49160, episodic_return=[0.]\n",
      "global_step=49280, episodic_return=[0.]\n",
      "global_step=49521, episodic_return=[3.]\n",
      "global_step=49639, episodic_return=[0.]\n",
      "global_step=49863, episodic_return=[3.]\n",
      "global_step=49981, episodic_return=[0.]\n",
      "global_step=50099, episodic_return=[0.]\n",
      "global_step=50244, episodic_return=[1.]\n",
      "global_step=50364, episodic_return=[0.]\n",
      "global_step=50484, episodic_return=[0.]\n",
      "global_step=50807, episodic_return=[5.]\n",
      "global_step=50951, episodic_return=[1.]\n",
      "global_step=51189, episodic_return=[3.]\n",
      "global_step=51452, episodic_return=[3.]\n",
      "global_step=51572, episodic_return=[0.]\n",
      "global_step=52014, episodic_return=[10.]\n",
      "global_step=52334, episodic_return=[5.]\n",
      "global_step=52510, episodic_return=[2.]\n",
      "global_step=52673, episodic_return=[1.]\n",
      "global_step=52793, episodic_return=[0.]\n",
      "global_step=52913, episodic_return=[0.]\n",
      "global_step=53061, episodic_return=[1.]\n",
      "global_step=53225, episodic_return=[1.]\n",
      "global_step=53416, episodic_return=[2.]\n",
      "global_step=53677, episodic_return=[3.]\n",
      "global_step=53793, episodic_return=[0.]\n",
      "global_step=53986, episodic_return=[2.]\n",
      "global_step=54106, episodic_return=[0.]\n",
      "global_step=54222, episodic_return=[0.]\n",
      "global_step=54413, episodic_return=[2.]\n",
      "global_step=54652, episodic_return=[3.]\n",
      "global_step=54770, episodic_return=[0.]\n",
      "global_step=54886, episodic_return=[0.]\n",
      "global_step=55004, episodic_return=[0.]\n",
      "global_step=55124, episodic_return=[0.]\n",
      "global_step=55589, episodic_return=[10.]\n",
      "global_step=55709, episodic_return=[0.]\n",
      "global_step=55952, episodic_return=[3.]\n",
      "global_step=56072, episodic_return=[0.]\n",
      "global_step=56220, episodic_return=[1.]\n",
      "global_step=56338, episodic_return=[0.]\n",
      "global_step=56458, episodic_return=[0.]\n",
      "global_step=56578, episodic_return=[0.]\n",
      "global_step=56696, episodic_return=[0.]\n",
      "global_step=56814, episodic_return=[0.]\n",
      "global_step=57027, episodic_return=[2.]\n",
      "global_step=57326, episodic_return=[5.]\n",
      "global_step=57489, episodic_return=[1.]\n",
      "global_step=57607, episodic_return=[0.]\n",
      "global_step=57725, episodic_return=[0.]\n",
      "global_step=57891, episodic_return=[1.]\n",
      "global_step=58011, episodic_return=[0.]\n",
      "global_step=58300, episodic_return=[4.]\n",
      "global_step=58418, episodic_return=[0.]\n",
      "global_step=58613, episodic_return=[2.]\n",
      "global_step=58790, episodic_return=[2.]\n",
      "global_step=58952, episodic_return=[1.]\n",
      "global_step=59272, episodic_return=[5.]\n",
      "global_step=59641, episodic_return=[6.]\n",
      "global_step=59757, episodic_return=[0.]\n",
      "global_step=59950, episodic_return=[2.]\n",
      "global_step=60143, episodic_return=[2.]\n",
      "global_step=60309, episodic_return=[1.]\n",
      "global_step=60427, episodic_return=[0.]\n",
      "global_step=60547, episodic_return=[0.]\n",
      "global_step=60829, episodic_return=[4.]\n",
      "global_step=61021, episodic_return=[2.]\n",
      "global_step=61137, episodic_return=[0.]\n",
      "global_step=61255, episodic_return=[0.]\n",
      "global_step=61373, episodic_return=[0.]\n",
      "global_step=61493, episodic_return=[0.]\n",
      "global_step=61739, episodic_return=[3.]\n",
      "global_step=62000, episodic_return=[3.]\n",
      "global_step=62118, episodic_return=[0.]\n",
      "global_step=62478, episodic_return=[5.]\n",
      "global_step=62672, episodic_return=[2.]\n",
      "global_step=62790, episodic_return=[0.]\n",
      "global_step=62910, episodic_return=[0.]\n",
      "global_step=63231, episodic_return=[5.]\n",
      "global_step=63347, episodic_return=[0.]\n",
      "global_step=63639, episodic_return=[4.]\n",
      "global_step=63930, episodic_return=[4.]\n",
      "global_step=64048, episodic_return=[0.]\n",
      "global_step=64358, episodic_return=[4.]\n",
      "global_step=64551, episodic_return=[2.]\n",
      "global_step=64695, episodic_return=[1.]\n",
      "global_step=64813, episodic_return=[0.]\n",
      "global_step=65034, episodic_return=[3.]\n",
      "global_step=65277, episodic_return=[3.]\n",
      "global_step=65468, episodic_return=[2.]\n",
      "global_step=65584, episodic_return=[0.]\n",
      "global_step=65702, episodic_return=[0.]\n",
      "global_step=65868, episodic_return=[1.]\n",
      "global_step=65988, episodic_return=[0.]\n",
      "global_step=66437, episodic_return=[10.]\n",
      "global_step=66601, episodic_return=[1.]\n",
      "global_step=66891, episodic_return=[4.]\n",
      "global_step=67009, episodic_return=[0.]\n",
      "global_step=67349, episodic_return=[5.]\n",
      "global_step=67709, episodic_return=[8.]\n",
      "global_step=67825, episodic_return=[0.]\n",
      "global_step=67945, episodic_return=[0.]\n",
      "global_step=68063, episodic_return=[0.]\n",
      "global_step=68300, episodic_return=[3.]\n",
      "global_step=68418, episodic_return=[0.]\n",
      "global_step=68791, episodic_return=[6.]\n",
      "global_step=68980, episodic_return=[2.]\n",
      "global_step=69098, episodic_return=[0.]\n",
      "global_step=69246, episodic_return=[1.]\n",
      "global_step=69509, episodic_return=[3.]\n",
      "global_step=69702, episodic_return=[2.]\n",
      "global_step=69945, episodic_return=[3.]\n",
      "global_step=70065, episodic_return=[0.]\n",
      "global_step=70181, episodic_return=[0.]\n",
      "global_step=70533, episodic_return=[6.]\n",
      "global_step=70653, episodic_return=[0.]\n",
      "global_step=70890, episodic_return=[3.]\n",
      "global_step=71054, episodic_return=[1.]\n",
      "global_step=71170, episodic_return=[0.]\n",
      "global_step=71338, episodic_return=[1.]\n",
      "global_step=71454, episodic_return=[0.]\n",
      "global_step=71574, episodic_return=[0.]\n",
      "global_step=71834, episodic_return=[3.]\n",
      "global_step=71954, episodic_return=[0.]\n",
      "global_step=72145, episodic_return=[2.]\n",
      "global_step=72395, episodic_return=[4.]\n",
      "global_step=72561, episodic_return=[1.]\n",
      "global_step=72675, episodic_return=[0.]\n",
      "global_step=72965, episodic_return=[4.]\n",
      "global_step=73081, episodic_return=[0.]\n",
      "global_step=73325, episodic_return=[3.]\n",
      "global_step=73441, episodic_return=[0.]\n",
      "global_step=73605, episodic_return=[1.]\n",
      "global_step=73721, episodic_return=[0.]\n",
      "global_step=73884, episodic_return=[1.]\n",
      "global_step=74033, episodic_return=[1.]\n",
      "global_step=74153, episodic_return=[0.]\n",
      "global_step=74319, episodic_return=[1.]\n",
      "global_step=74488, episodic_return=[1.]\n",
      "global_step=74685, episodic_return=[2.]\n",
      "global_step=74805, episodic_return=[0.]\n",
      "global_step=75113, episodic_return=[4.]\n",
      "global_step=75229, episodic_return=[0.]\n",
      "global_step=75438, episodic_return=[2.]\n",
      "global_step=75558, episodic_return=[0.]\n"
     ]
    }
   ],
   "source": [
    "def make_env(env_id, seed, idx, capture_video, run_name):\n",
    "    def thunk():\n",
    "        env = gym.make(env_id, render_mode=\"rgb_array\")\n",
    "        env = gym.wrappers.RecordEpisodeStatistics(env)\n",
    "\n",
    "        if capture_video and idx == 0:\n",
    "            env = gym.wrappers.RecordVideo(env, f\"videos/{run_name}\", episode_trigger=lambda e: e % 1000 == 0)\n",
    "\n",
    "        env = NoopResetEnv(env, noop_max=30)\n",
    "        env = MaxAndSkipEnv(env, skip=4)\n",
    "        env = EpisodicLifeEnv(env)\n",
    "\n",
    "        if \"FIRE\" in env.unwrapped.get_action_meanings():\n",
    "            env = FireResetEnv(env)\n",
    "\n",
    "        env = ClipRewardEnv(env)\n",
    "        env = WarpFrame(env)\n",
    "        env = FrameStackObservation(env, 4)\n",
    "\n",
    "        env.reset(seed=seed)\n",
    "        env.action_space.seed(seed)\n",
    "        env.observation_space.seed(seed)\n",
    "        return env\n",
    "    return thunk\n",
    "\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, env):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(4, 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3136, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, env.single_action_space.n)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input should already be normalized from preprocessing\n",
    "        return self.network(x / 255.0)\n",
    "\n",
    "\n",
    "def linear_schedule(start_e: float, end_e: float, duration: int, t: int):\n",
    "    slope = (end_e - start_e) / duration\n",
    "    return max(slope * t + start_e, end_e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(params.batch_size)\n",
    "    run_name = f\"{params.env_id}__{params.exp_name}__{params.seed}__{int(time.time())}\"\n",
    "\n",
    "    random.seed(params.seed)\n",
    "    np.random.seed(params.seed)\n",
    "    torch.manual_seed(params.seed)\n",
    "    torch.backends.cudnn.deterministic = params.torch_deterministic\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "\n",
    "    # env setup\n",
    "    envs = gym.vector.SyncVectorEnv([make_env(params.env_id, params.seed, 0, params.capture_video, run_name)])\n",
    "    assert isinstance(envs.single_action_space, gym.spaces.Discrete), \"only discrete action space is supported\"\n",
    "\n",
    "    q_network = QNetwork(envs).to(device)\n",
    "    optimizer = optim.AdamW(q_network.parameters(), lr=params.learning_rate, weight_decay=1e-3)\n",
    "    target_network = QNetwork(envs).to(device)\n",
    "    target_network.load_state_dict(q_network.state_dict())\n",
    "\n",
    "    rb = ReplayBuffer(\n",
    "        params.buffer_size,\n",
    "        envs.single_observation_space,\n",
    "        envs.single_action_space,\n",
    "        device,\n",
    "        optimize_memory_usage=True,\n",
    "        handle_timeout_termination=False,\n",
    "    )\n",
    "\n",
    "    #take an action\n",
    "    obs, infos = envs.reset()\n",
    "    for global_step in range(params.total_timesteps):\n",
    "        epsilon = linear_schedule(params.start_e, params.end_e, params.exploration_fraction * params.total_timesteps, global_step)\n",
    "            \n",
    "        if random.random() < epsilon:\n",
    "            actions = np.array([envs.single_action_space.sample()])\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                # Fix: Handle dimension properly - squeeze out extra dimensions\n",
    "                obs_tensor = torch.tensor(obs, device=device, dtype=torch.float32).squeeze(-1)\n",
    "                q_values = q_network(obs_tensor)\n",
    "                actions = torch.argmax(q_values, dim=1).cpu().numpy()\n",
    "\n",
    "        # Take a step in the environment\n",
    "        next_obs, rewards, terminations, truncations, infos = envs.step(actions)\n",
    "        dones = np.logical_or(terminations, truncations)\n",
    "\n",
    "        # Print reward info\n",
    "        if \"episode\" in infos.keys():\n",
    "            print(f\"global_step={global_step}, episodic_return={infos['episode']['r']}\")\n",
    "\n",
    "        # Fix: Remove syntax error - 's' before next_obs\n",
    "        real_next_obs = next_obs.copy()\n",
    "\n",
    "        # Store transitions in replay buffer\n",
    "        processed_infos = [{} for _ in range(envs.num_envs)]\n",
    "        rb.add(obs, real_next_obs, actions, rewards, dones, processed_infos)\n",
    "\n",
    "        obs = next_obs\n",
    "        \n",
    "        # Training\n",
    "        if global_step > params.learning_starts:\n",
    "            if global_step % params.train_frequency == 0:\n",
    "                data = rb.sample(params.batch_size)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    # Fix: Squeeze out extra dimensions for target network\n",
    "                    next_q_values = target_network(data.next_observations.float().squeeze(-1))\n",
    "                    target_max = next_q_values.max(dim=1)[0]  # Get values, not indices\n",
    "                    \n",
    "                    # Fix: Proper reward and done tensor handling\n",
    "                    rewards_tensor = data.rewards.flatten()\n",
    "                    dones_tensor = data.dones.flatten()\n",
    "                    \n",
    "                    td_target = rewards_tensor + params.gamma * target_max * (1 - dones_tensor)\n",
    "\n",
    "                # Fix: Current Q-values calculation with proper dimensions\n",
    "                current_q_values = q_network(data.observations.float().squeeze(-1))\n",
    "                old_val = current_q_values.gather(1, data.actions.long()).squeeze()\n",
    "\n",
    "                loss = F.mse_loss(old_val, td_target)\n",
    "\n",
    "                # Gradient step\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Update target network\n",
    "            if global_step % params.target_network_frequency == 0:\n",
    "                for target_param, q_param in zip(target_network.parameters(), q_network.parameters()):\n",
    "                    target_param.data.copy_(\n",
    "                        params.tau * q_param.data + (1.0 - params.tau) * target_param.data\n",
    "                    )\n",
    "\n",
    "    if params.save_model:\n",
    "        model_path = f\"runs/{run_name}/{params.exp_name}_model\"\n",
    "        os.makedirs(f\"runs/{run_name}\", exist_ok=True)\n",
    "        torch.save(q_network.state_dict(), model_path)\n",
    "        print(f\"model saved to {model_path}\")\n",
    "\n",
    "    envs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fcba02-056e-411d-9aec-7605a26984f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
